{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 feature extraction\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(4)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(4)\n",
    "\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/usr/lib/spark2')\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_SUBMIT_ARGS'] = ' --archives tf-env-2.4.zip#venv pyspark-shell'\n",
    "os.environ['PYSPARK_PYTHON'] = 'venv/bin/python'\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName('ResNet50')\n",
    "    .master('yarn')\n",
    "    .config(\n",
    "        'spark.driver.extraJavaOptions',\n",
    "        ' '.join('-D{}={}'.format(k, v) for k, v in {\n",
    "            'http.proxyHost': 'webproxy.eqiad.wmnet',\n",
    "            'http.proxyPort': '8080',\n",
    "            'https.proxyHost': 'webproxy.eqiad.wmnet',\n",
    "            'https.proxyPort': '8080',\n",
    "        }.items()))\n",
    "    .config('spark.jars.packages', 'org.apache.spark:spark-avro_2.11:2.4.4')\n",
    "    .config(\"spark.driver.memory\", \"4g\") \n",
    "    .config('spark.dynamicAllocation.maxExecutors', 128) \n",
    "    .config(\"spark.executor.memory\", \"8g\") \n",
    "    .config(\"spark.executor.cores\", 4) \n",
    "    .config(\"spark.sql.shuffle.partitions\", 512)\n",
    "    .config(\"spark.sql.execution.arrow.maxRecordsPerBatch\", 1024)\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data into Spark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = spark.read.format('avro').load('image.avro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- i: integer (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- project: string (nullable = true)\n",
      " |-- image_file_name: string (nullable = true)\n",
      " |-- thumbnail_size: string (nullable = true)\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- image_bytes_b64: string (nullable = true)\n",
      " |    |-- format: string (nullable = true)\n",
      " |    |-- width: integer (nullable = true)\n",
      " |    |-- height: integer (nullable = true)\n",
      " |    |-- image_bytes_sha1: string (nullable = true)\n",
      " |    |-- error: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pixels.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(weights='imagenet', pooling='max', include_top=False)\n",
    "model_json = model.to_json()\n",
    "bc_model_weights = sc.broadcast(model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run model inference via pandas UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "\n",
    "@F.pandas_udf(returnType=ArrayType(FloatType()))\n",
    "def extract_features(image_bytes):\n",
    "    images = []\n",
    "    for row in image_bytes:\n",
    "        try:\n",
    "            img = Image.open(BytesIO(base64.b64decode(row))).convert('RGB').resize([image_size, image_size])\n",
    "        except:\n",
    "            images.append(np.zeros((image_size, image_size, 3), dtype=np.float32))\n",
    "        else:\n",
    "            images.append(np.asarray(img, dtype=np.float32))\n",
    "    model = model_from_json(model_json)\n",
    "    model.set_weights(bc_model_weights.value)\n",
    "    images = np.vstack(images)\n",
    "    images = images.reshape((-1,image_size,image_size,3))\n",
    "    x = np.copy(images)\n",
    "    x = preprocess_input(x)\n",
    "    features = model.predict(x)\n",
    "    return pd.Series([row.tolist() for row in features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pixels\n",
    "    .withColumn(\"features\", extract_features(F.col(\"image.image_bytes_b64\")))\n",
    "    .select(\"i\",\"image_file_name\",\"features\",\"image_url\")\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .parquet('output.parquet')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and check the prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = spark.read.load('output.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+\n",
      "|      i|     image_file_name|            features|           image_url|\n",
      "+-------+--------------------+--------------------+--------------------+\n",
      "| 662714|Seribu_Rumah_Gada...|[3.1161337, 2.381...|https://upload.wi...|\n",
      "|2816800|DM_Rad_2017_Männe...|[0.97691995, 4.64...|https://upload.wi...|\n",
      "|1752258|Jackie_Chan_TIFF_...|[7.088956, 4.9775...|https://upload.wi...|\n",
      "|2373722|      Amblypigid.jpg|[0.44165516, 4.50...|http://upload.wik...|\n",
      "|2156691|Keski-Uudenmaan_p...|[10.556867, 3.813...|https://upload.wi...|\n",
      "|3267094|GuentherZ_2012-02...|[1.130087, 2.2200...|https://upload.wi...|\n",
      "|1334754|RO_B_Batiste_chur...|[1.3544466, 11.27...|https://upload.wi...|\n",
      "| 305959|  Biokilereaktor.png|[1.8614346, 6.087...|https://upload.wi...|\n",
      "|3238121|Saint_Davids_Naas...|[4.4893565, 8.195...|https://upload.wi...|\n",
      "|1928771|Waltraud_Starck_2...|[1.0994802, 5.066...|https://upload.wi...|\n",
      "| 276264|    LA2_vemardet.jpg|[4.3736835, 0.595...|https://upload.wi...|\n",
      "|3175083|Margueray_-_Églis...|[2.0219932, 4.172...|https://upload.wi...|\n",
      "|1316087|RAMON_FRANCO_AÑO_...|[3.373425, 6.3277...|http://upload.wik...|\n",
      "| 398104|Montmachoux-FR-77...|[2.2433548, 3.423...|https://upload.wi...|\n",
      "|2532855|Antonio_Zamorano.jpg|[3.3001566, 8.736...|http://upload.wik...|\n",
      "| 231278|Tony_Kushner_-_Ho...|[0.0, 0.0, 0.0, 7...|https://upload.wi...|\n",
      "| 871248|Front_Teatr_Slask...|[1.2973222, 5.037...|https://upload.wi...|\n",
      "| 373528|Berny-Rivière_(Ai...|[3.344163, 5.6872...|https://upload.wi...|\n",
      "| 873872|Town_Hall,_Llanid...|[3.9575052, 4.738...|https://upload.wi...|\n",
      "|1042630|WVMap-doton-Bluef...|[1.7039187, 4.114...|https://upload.wi...|\n",
      "+-------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
