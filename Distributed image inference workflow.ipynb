{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed image inference workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following workflow describes how to do model inference with Tensorflow/Keras in Analytics cluster for deep learning image-related applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 0: Configure the necessary settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Configure Tensorflow: In case Tensorflow tasks to take all available resources (see https://wikitech.wikimedia.org/wiki/Analytics/Systems/Cluster/AMD_GPU#Configure_your_Tensorflow_script) \n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(4) #or lower values\n",
    "tf.config.threading.set_inter_op_parallelism_threads(4) #or lower values\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Configure a custom PySpark SparkSession\n",
    "    1. Ship the local conda stack/environment to Hadoop workers: The idea is to create a compressed env file then pass to workers via Spark's args. Note that a ***non-ROCm tensorflow*** need to be installed in the conda environment that ship to Hadoop workers, since we will use CPU on Hadoop workers to run the inference jobs.\n",
    "    \n",
    "    `os.environ['PYSPARK_SUBMIT_ARGS'] = '--archives tf-env-2.4.zip#venv pyspark-shell'`\n",
    "    \n",
    "    2. Configure Apache Arrow to decrease the batch size of the Arrorw reader to avoid OOM errors on smaller instance types:\n",
    "\n",
    "    `.config('spark.sql.execution.arrow.maxRecordsPerBatch', 1024) `\n",
    "    \n",
    "    3. Depending on the data type, import external packages:\n",
    "        * TFRecords: use linkdin's [spark-tfrecord](https://github.com/linkedin/spark-tfrecord) \n",
    "        \n",
    "        `.config('spark.jars.packages', 'com.linkedin.sparktfrecord:spark-tfrecord_2.11:0.2.4')`\n",
    "        * Avro: use [spark-avro](https://spark.apache.org/docs/2.4.0/sql-data-sources-avro.html)\n",
    "        \n",
    "        `.config('spark.jars.packages', 'org.apache.spark:spark-avro_2.11:2.4.4')`\n",
    "    \n",
    "    More detail on how to launch a Custom PySpark SparkSession, please refer to https://wikitech.wikimedia.org/wiki/Analytics/Systems/Jupyter/Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Prepare trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to broadcast the weights of the model from the driver, load the model graph and get the weights from the broadcasted variables in a pandas UDF.\n",
    "\n",
    "##### Example 1: Load a saved trained model:\n",
    "\n",
    "```python\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "model = keras.models.load_model('/path/to/model/')\n",
    "model_json = model.to_json()\n",
    "bc_model_weights = sc.broadcast(model.get_weights())\n",
    "```\n",
    "\n",
    "* Be sure to install numpy<1.20, since `load_model` might have trouble to work with numpy==1.20 (see https://stackoverflow.com/questions/58479556)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example 2: Load ResNet50:\n",
    "```python\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "model = ResNet50()\n",
    "bc_model_weights = sc.broadcast(model.get_weights())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example 3: Load ResNet50 excludes the top layer for feature extraction:\n",
    "\n",
    "```python\n",
    "model = ResNet50(weights='imagenet', pooling='max', include_top=False)\n",
    "model_json = model.to_json()\n",
    "bc_model_weights = sc.broadcast(model.get_weights())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Prepare data for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your image data is on local/stat machine, we recommend first to save images into TFRecord.\n",
    "\n",
    "* An example script to save image data to TFRecord file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "data_dir = pathlib.Path('/home/aikochou/VisualGap/models/quality_model/Pixels/')\n",
    "quality_img = list(data_dir.glob('Quality/Quality/*.jpg'))[:50]\n",
    "random_img = list(data_dir.glob('Random/Random/*.jpg'))[:50]\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def image_example(image_file_name, image_bytes, label):\n",
    "    feature = {\n",
    "      'image_file_name': _bytes_feature(image_file_name),\n",
    "      'image_bytes': _bytes_feature(image_bytes),\n",
    "      'label': _int64_feature(label),\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "file_name = 'output.tfrecords'\n",
    "with tf.io.TFRecordWriter(file_name) as writer:\n",
    "    for img, label in [(img, 1) for img in quality_img]+[(img, 0) for img in random_img]:\n",
    "        try:\n",
    "            image = Image.open(img).convert('RGB')\n",
    "            img_byte_arr = BytesIO()\n",
    "            image.save(img_byte_arr, format='JPEG')\n",
    "            tf_example = image_example(str(img).split('/')[-1].encode('utf-8'),img_byte_arr.getvalue(),label)\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Move the TFRecord file to HDFS:\n",
    "\n",
    "    `hadoop fs -moveFromLocal <file_name> <hdfs_dir>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Load the data into Spark DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example 1: Load TFRecords into Spark DataFrames\n",
    "    \n",
    "   When loading TFRecords using linkdin's spark-tfrecord, you need to specify the schema explicitly (see https://github.com/tensorflow/ecosystem/issues/123)\n",
    "\n",
    "```python\n",
    "df = (spark.read.schema('image_file_name string, image_bytes binary, label int').format(\"tfrecord\")\n",
    "        .option('recordType', 'Example').load('/path/to/file/in/hdfs'))\n",
    "```\n",
    "\n",
    "##### Example 2: Load Avro into Spark DataFrames\n",
    "\n",
    "```python\n",
    "pixels = spark.read.format('avro').load('/path/to/file/in/hdfs')\n",
    "pixels.printSchema()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Run model inference via pandas UDF and save prediction results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocess input data\n",
    "* Convert the bytes to numpy.array\n",
    "\n",
    "```python\n",
    "from io import BytesIO\n",
    "image_size = 180\n",
    "\n",
    "@F.pandas_udf(ArrayType(FloatType()))\n",
    "def process_image(image_bytes):\n",
    "    ret = []\n",
    "    for image in image_bytes:\n",
    "        im = Image.open(BytesIO(image))\n",
    "        im = im.resize([image_size,image_size])\n",
    "        image_data = [float(i) for i in np.asarray(im, dtype='float32').flatten()]\n",
    "        ret.append(image_data)\n",
    "    return pd.Series(ret)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define the function to parse the input data.\n",
    "\n",
    "```python\n",
    "def parse_image(image_data):\n",
    "    image = tf.image.convert_image_dtype(image_data, dtype=tf.float32) * (2. / 255) - 1 # normalization\n",
    "    image = tf.reshape(image,[IMAGE_SIZE,IMAGE_SIZE,3])\n",
    "    return image\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define the function for model inference\n",
    "\n",
    "To load data in batches, using the `tf.data` API is recommended which support prefetching and multi-threaded loading to hide IO bound latency.\n",
    "\n",
    "```python\n",
    "@F.pandas_udf(ArrayType(FloatType()))\n",
    "def predict_batch_udf(image_batch):\n",
    "    batch_size = 64\n",
    "    model = model_from_json(model_json) # load the model graph \n",
    "    model.set_weights(bc_model_weights.value) # set the weights from the broadcasted variables\n",
    "    images = np.vstack(image_batch)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(images)\n",
    "    dataset = dataset.map(parse_image, num_parallel_calls=8).prefetch(5000).batch(batch_size)\n",
    "    preds = model.predict(dataset)\n",
    "    return pd.Series(list(preds))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a complete pretrained model from keras.application, load the model graph directly in the pandas UDF:\n",
    "```python\n",
    "model = ResNet50(weights=None)\n",
    "```\n",
    "\n",
    "For a part of pretrained model or a model you trained, load the model graph from json:\n",
    "```python\n",
    "model = model_from_json(model_json)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run model prediction and save prediction results back to Hive\n",
    "\n",
    "```python\n",
    "(df\n",
    " .withColumn('image_arr', process_image(F.col('image_bytes')))\n",
    " .withColumn('prediction', predict_batch_udf(F.col('image_arr')))\n",
    " .write\n",
    " .mode('overwrite')\n",
    " .option('path', '/path/to/save/table')\n",
    " .saveAsTable('aikochou.testTable')\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to save to parquet only:\n",
    "\n",
    "```python\n",
    "(df\n",
    " .withColumn('image_arr', process_image(F.col('image_bytes')))\n",
    " .withColumn('prediction', predict_batch_udf(F.col('image_arr')))\n",
    " .write\n",
    " .mode('overwrite')\n",
    " .parquet('/path/to/output/file')\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Make the result Hive table public"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the table public, you’ll have to change permission to the files in HDFS, and make them read available to the analytics group `analytics-privatedata-users`\n",
    "\n",
    "* To change group ownership to and HDFS directory you have to use this command:\n",
    "\n",
    "    `hadoop fs -chown :analytics-privatedata-users -R /path/to/your/table`\n",
    "    \n",
    "* Be sure to make the data group readable with:\n",
    "\n",
    "    `hadoop fs -chmod g+r /path/to/your/table`\n",
    "    \n",
    "* Also make your user directory readable and executable:\n",
    "\n",
    "    `hadoop fs -chmod o=rx /user/aikochou`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
